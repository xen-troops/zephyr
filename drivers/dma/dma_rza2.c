/*
 * Copyright (c) 2023 EPAM Systems
 *
 * SPDX-License-Identifier: Apache-2.0
 */
#include <stddef.h>
#include <zephyr/device.h>
#include <zephyr/dt-bindings/dma/rza2_dma.h>
#include <zephyr/drivers/dma.h>
#ifdef CONFIG_PINCTRL
#include <zephyr/drivers/pinctrl.h>
#endif
#include <zephyr/logging/log.h>
#include <zephyr/spinlock.h>
#include <zephyr/irq.h>

#define DT_DRV_COMPAT renesas_rza2_dma

#define RZA2_DMA_CH_OFFT        0x40
#define RZA2_DMA_CH_8_15_OFFSET 0x400

BUILD_ASSERT(CONFIG_DMA_RZA2_INIT_PRIORITY > CONFIG_INTC_INIT_PRIORITY,
	     "DMA_RZA2_INIT_PRIORITY must be higher than CONFIG_INTC_INIT_PRIORITY");

#define GET_SECTION_OFF(n) ((n > 7) ? RZA2_DMA_CH_8_15_OFFSET : 0)

#define GET_CNUM_OFF(n) (RZA2_DMA_CH_OFFT * (n & 7))

#define GET_CH_OFF(dev, n)                                                                         \
	(DEVICE_MMIO_NAMED_GET(dev, reg_main) + GET_SECTION_OFF(n) + GET_CNUM_OFF(n))

#define GET_DC_OFF(dev, n) (DEVICE_MMIO_NAMED_GET(dev, reg_main) + GET_SECTION_OFF(n))

#define N0SA(dev, n)   (GET_CH_OFF(dev, n) + 0x0)
#define N0DA(dev, n)   (GET_CH_OFF(dev, n) + 0x4)
#define N0TB(dev, n)   (GET_CH_OFF(dev, n) + 0x8)
#define N1SA(dev, n)   (GET_CH_OFF(dev, n) + 0xc)
#define N1DA(dev, n)   (GET_CH_OFF(dev, n) + 0x10)
#define N1TB(dev, n)   (GET_CH_OFF(dev, n) + 0x14)
#define CRSA(dev, n)   (GET_CH_OFF(dev, n) + 0x18)
#define CRDA(dev, n)   (GET_CH_OFF(dev, n) + 0x1c)
#define CRTB(dev, n)   (GET_CH_OFF(dev, n) + 0x20)
#define CHSTAT(dev, n) (GET_CH_OFF(dev, n) + 0x24)
#define CHCTRL(dev, n) (GET_CH_OFF(dev, n) + 0x28)
#define CHCFG(dev, n)  (GET_CH_OFF(dev, n) + 0x2c)
#define CHITVL(dev, n) (GET_CH_OFF(dev, n) + 0x30)
#define CHEXT(dev, n)  (GET_CH_OFF(dev, n) + 0x34)
#define NXLA(dev, n)   (GET_CH_OFF(dev, n) + 0x38)
#define CRLA(dev, n)   (GET_CH_OFF(dev, n) + 0x3c)

/* Common registers */
#define DCTRL(dev, n)     (GET_DC_OFF(dev, n) + 0x300)
#define DSTAT_EN(dev, n)  (GET_DC_OFF(dev, n) + 0x310)
#define DSTAT_ER(dev, n)  (GET_DC_OFF(dev, n) + 0x314)
#define DSTAT_END(dev, n) (GET_DC_OFF(dev, n) + 0x318)
#define DSTAT_TC(dev, n)  (GET_DC_OFF(dev, n) + 0x31c)
#define DSTAT_SUS(dev, n) (GET_DC_OFF(dev, n) + 0x320)

/*
 * Extended in range of 0..7 from "ext" region.
 * Reg is uint32_t with CHn in 0 -> 9 bits and CHn+1 in 16->25 bits
 */
#define DMARS(dev, n) (DEVICE_MMIO_NAMED_GET(dev, ext) + ((n / 0x2) * 4))

LOG_MODULE_REGISTER(dma_rza2, CONFIG_DMA_LOG_LEVEL);

/*
 * Link mode descriptor definitions
 */
#define HDR_LV  BIT(0) /* Indicates whether descriptor is valid */
#define HDR_LE  BIT(1) /* Indicated whether link ends */
#define HDR_WBD BIT(2) /* Write Back Disable */
#define HDR_DIM BIT(3) /* Interrupt Mask */

#define DMAC_PRV_CHCFG_SET_DMS          (0x80000000U)
#define DMAC_PRV_CHCFG_SET_REN          (0x40000000U)
#define DMAC_PRV_CHCFG_MASK_REN         (0x40000000U)
#define DMAC_PRV_CHCFG_SET_RSW          (0x20000000U)
#define DMAC_PRV_CHCFG_MASK_RSW         (0x20000000U)
#define DMAC_PRV_CHCFG_SET_RSEL         (0x10000000U)
#define DMAC_PRV_CHCFG_MASK_RSEL        (0x10000000U)
#define DMAC_PRV_CHCFG_MASK_SBE         (0x08000000U)
#define DMAC_PRV_CHCFG_SET_DEM          (0x01000000U)
#define DMAC_PRV_CHCFG_MASK_DEM         (0x01000000U)
#define DMAC_PRV_CHCFG_SET_TM           (0x00400000U)
#define DMAC_PRV_CHCFG_MASK_DAD         (0x00200000U)
#define DMAC_PRV_CHCFG_MASK_SAD         (0x00100000U)
#define DMAC_PRV_CHCFG_MASK_DDS         (0x000f0000U)
#define DMAC_PRV_CHCFG_MASK_SDS         (0x0000f000U)
#define DMAC_PRV_CHCFG_SET_AM_LEVEL     (0x00000100U)
#define DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE (0x00000200U)
#define DMAC_PRV_CHCFG_MASK_AM          (0x00000700U)
#define DMAC_PRV_CHCFG_SET_LVL_EDGE     (0x00000000U)
#define DMAC_PRV_CHCFG_SET_LVL_LEVEL    (0x00000040U)
#define DMAC_PRV_CHCFG_MASK_LVL         (0x00000040U)
#define DMAC_PRV_CHCFG_SET_REQD_SRC     (0x00000000U)
#define DMAC_PRV_CHCFG_SET_REQD_DST     (0x00000008U)
#define DMAC_PRV_CHCFG_MASK_REQD        (0x00000008U)
#define DMAC_PRV_CHCFG_SHIFT_SBE        (27U)
#define DMAC_PRV_CHCFG_SHIFT_DAD        (21U)
#define DMAC_PRV_CHCFG_SHIFT_SAD        (20U)
#define DMAC_PRV_CHCFG_SHIFT_DDS        (16U)
#define DMAC_PRV_CHCFG_SHIFT_SDS        (12U)
#define DMAC_PRV_CHCFG_SHIFT_AM         (8U)
#define DMAC_PRV_CHCFG_SHIFT_REQD       (3U)
#define DMAC_PRV_CHCFG_SHIFT_LOEN       (4U)
#define DMAC_PRV_CHCFG_SHIFT_HIEN       (5U)
#define DMAC_PRV_CHCFG_SHIFT_LVL        (6U)

/* REQD value in CHCFG is undefined on configuration table */
#define DMAC_PRV_CHCFG_REQD_UNDEFINED (2)

/* CHEXT */
#define DMAC_PRV_CHEXT_SET_DCA_NORMAL        (0x00003000U)
#define DMAC_PRV_CHEXT_SET_DCA_STRONG        (0x00000000U)
#define DMAC_PRV_CHEXT_SET_DPR_NON_SECURE    (0x00000200U)
#define DMAC_PRV_CHEXT_SET_SCA_NORMAL        (0x00000030U)
#define DMAC_PRV_CHEXT_SET_SCA_STRONG        (0x00000000U)
#define DMAC_PRV_CHEXT_SET_SPR_NON_SECURE    (0x00000002U)

/* Address of area which is the target of setting change */
#define DMAC_PRV_DMA_EXTERNAL_BUS_START         (0x00000000U)
#define DMAC_PRV_DMA_EXTERNAL_BUS_END           (0x1FFFFFFFU)
#define DMAC_PRV_DMA_EXTERNAL_BUS_MIRROR_START  (0x40000000U)
#define DMAC_PRV_DMA_EXTERNAL_BUS_MIRROR_END    (0x5FFFFFFFU)

#define CLRINTMSK    BIT(17)
#define SETINTMSK    BIT(16)
#define CLRSUS       BIT(9)
#define SETSUS       BIT(8)
#define CLRTC        BIT(6)
#define CLREND       BIT(5)
#define CLRRQ        BIT(4)
#define SWRST        BIT(3)
#define STG          BIT(2)
#define CLREN        BIT(1)
#define SETEN        BIT(0)
#define CHCTRL_CLEAR (CLRINTMSK | CLRSUS | CLRTC | CLREND | CLRRQ | SWRST | CLREN)

#define DMAC_PRV_CHSTAT_MASK_DER  (BIT(10))
#define DMAC_PRV_CHSTAT_MASK_SR   (BIT(7))
#define DMAC_PRV_CHSTAT_MASK_END  (BIT(5))
#define DMAC_PRV_CHSTAT_MASK_ER   (BIT(4))
#define DMAC_PRV_CHSTAT_MASK_TACT (BIT(2))
#define DMAC_PRV_CHSTAT_MASK_EN   (BIT(0))

#define IS_SET(value, mask) (!!((value) & (mask)))

struct rza2_dma_link_descriptor {
	uint32_t header;
	uint32_t src_addr;
	uint32_t dest_addr;
	uint32_t trans_byte;
	uint32_t config;
	uint32_t interval;
	uint32_t extension;
	uint32_t next_link_address;
};

struct dma_rza2_config {
	DEVICE_MMIO_NAMED_ROM(reg_main);
	DEVICE_MMIO_NAMED_ROM(ext);

	uint8_t num_channels;
	void (*irq_configure)(void);
	const struct pinctrl_dev_config *pcfg;
	uint32_t addr_alignment;
};

enum channel_mode {
	REGISTER_MODE = 0,
	LINK_MODE
};

struct dma_rza2_channel {
	int sw_trigger;
	bool busy;
	dma_callback_t dma_callback;
	void *user_data;
	int err_callback_en;
	int complete_callback_en;
	enum channel_mode mode;
	struct rza2_dma_link_descriptor *descrs;
	uint32_t total_bytes;
	uint32_t direction;
	int chunk;
	struct k_spinlock lock;
};

/* DMA channel configuration table */
struct dma_hw_config {
	uint8_t resource; /* should be equal to the index */
	uint32_t dmars;
	uint32_t tm_am;
	uint32_t lvl;
	uint32_t reqd;
};

BUILD_ASSERT(CONFIG_DMA_RZA2_DESCRS_CHUNKS <= 32,
	     "CONFIG_DMA_RZA2_DESCRS_CHUNKS > 32 is not supported\n");

/* DMA transfer resource */
static const struct dma_hw_config dma_hw_config_table[] = {
	/* resource,                 DMARS, CHCFG AM / TM                  , CHCFG LVL , CHCFG REQD
	 */
	{DMA_MEM_2_MEM, 0x0, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE | DMAC_PRV_CHCFG_SET_TM,
	 DMAC_PRV_CHCFG_SET_LVL_LEVEL, DMAC_PRV_CHCFG_REQD_UNDEFINED},

	{DMA_RS_OSTM0TINT, 0x023, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_OSTM1TINT, 0x073, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_OSTM2TINT, 0x02b, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},

	{DMA_RS_TGIA_0, 0x043, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIB_0, 0x047, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIC_0, 0x04B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGID_0, 0x04F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIA_1, 0x053, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIB_1, 0x057, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIA_2, 0x05B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIB_2, 0x05F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIA_3, 0x063, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIB_3, 0x067, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIC_3, 0x06B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGID_3, 0x06F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIA_4, 0x073, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIB_4, 0x077, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIC_4, 0x07B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGID_4, 0x07F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TCIV_4, 0x083, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIU_5, 0x087, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIV_5, 0x08B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIW_5, 0x08F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIA_6, 0x093, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIB_6, 0x097, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIC_6, 0x09B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGID_6, 0x09F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIA_7, 0x0A3, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIB_7, 0x0A7, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIC_7, 0x0AB, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGID_7, 0x0AF, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TCIV_7, 0x0B3, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIA_8, 0x0B7, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIB_8, 0x0BB, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGIC_8, 0x0BF, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_TGID_8, 0x0C3, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},

	{DMA_RS_GTCIA_0, 0x0C7, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIB_0, 0x0CB, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIC_0, 0x0CF, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCID_0, 0x0D3, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GDTE_0, 0x0D7, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIH_0, 0x0DB, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIL_0, 0x0DF, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIE_0, 0x0E3, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIF_0, 0x0E7, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIADA_0, 0x0EB, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIADB_0, 0x0EF, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIV_0, 0x0F3, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIU_0, 0x0F7, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},

	{DMA_RS_GTCIA_1, 0x0FB, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIB_1, 0x0FF, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIC_1, 0x103, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCID_1, 0x107, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GDTE_1, 0x10B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIH_1, 0x10F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIL_1, 0x113, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIE_1, 0x117, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIF_1, 0x11B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIADA_1, 0x11F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIADB_1, 0x123, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIV_1, 0x127, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIU_1, 0x12B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},

	{DMA_RS_GTCIA_2, 0x12F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIB_2, 0x133, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIC_2, 0x137, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCID_2, 0x13B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GDTE_2, 0x13F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIH_2, 0x143, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIL_2, 0x147, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIE_2, 0x14B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIF_2, 0x14F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIADA_2, 0x153, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIADB_2, 0x157, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIV_2, 0x15B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIU_2, 0x15F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},

	{DMA_RS_GTCIA_3, 0x163, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIB_3, 0x167, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIC_3, 0x16B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCID_3, 0x16F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GDTE_3, 0x173, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIH_3, 0x177, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIL_3, 0x17B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIE_3, 0x17F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIF_3, 0x183, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIADA_3, 0x187, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIADB_3, 0x18B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIV_3, 0x18F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIU_3, 0x193, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},

	{DMA_RS_GTCIA_4, 0x197, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIB_4, 0x19B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIC_4, 0x19F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCID_4, 0x1A3, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GDTE_4, 0x1A7, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIH_4, 0x1AB, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIL_4, 0x1AF, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIE_4, 0x1B3, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIF_4, 0x1B7, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIADA_4, 0x1BB, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIADB_4, 0x1BF, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIV_4, 0x1C3, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIU_4, 0x1C7, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},

	{DMA_RS_GTCIA_5, 0x1CB, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIB_5, 0x1CF, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIC_5, 0x1D3, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCID_5, 0x1D7, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GDTE_5, 0x1DB, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIH_5, 0x1DF, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIL_5, 0x1E3, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIE_5, 0x1E7, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIF_5, 0x1EB, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIADA_5, 0x1EF, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIADB_5, 0x1F3, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIV_5, 0x1F7, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIU_5, 0x1FB, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},

	{DMA_RS_GTCIA_6, 0x1FF, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIB_6, 0x203, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIC_6, 0x207, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCID_6, 0x20B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GDTE_6, 0x20F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIH_6, 0x213, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIL_6, 0x217, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIE_6, 0x21B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIF_6, 0x21F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIADA_6, 0x223, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIADB_6, 0x227, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIV_6, 0x22B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIU_6, 0x22F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},

	{DMA_RS_GTCIA_7, 0x233, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIB_7, 0x237, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIC_7, 0x23B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCID_7, 0x23F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GDTE_7, 0x243, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIH_7, 0x247, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIL_7, 0x24B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIE_7, 0x24F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIF_7, 0x253, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIADA_7, 0x257, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIADB_7, 0x25B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIV_7, 0x25F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_GTCIU_7, 0x263, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},

	{DMA_RS_S12ADI_0, 0x267, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_S12GBADI_0, 0x26B, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_S12GCADI_0, 0x26F, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},

	{DMA_RS_INT_SSIF_DMA_RX_0, 0x272, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE,
	 DMAC_PRV_CHCFG_SET_LVL_EDGE, DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_INT_SSIF_DMA_TX_0, 0x271, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE,
	 DMAC_PRV_CHCFG_SET_LVL_EDGE, DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_INT_SSIF_DMA_RX_1, 0x276, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE,
	 DMAC_PRV_CHCFG_SET_LVL_EDGE, DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_INT_SSIF_DMA_TX_1, 0x275, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE,
	 DMAC_PRV_CHCFG_SET_LVL_EDGE, DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_INT_SSIF_DMA_RX_2, 0x27B, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE,
	 DMAC_PRV_CHCFG_SET_LVL_EDGE, DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_INT_SSIF_DMA_TX_2, 0x27B, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE,
	 DMAC_PRV_CHCFG_SET_LVL_EDGE, DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_INT_SSIF_DMA_RX_3, 0x27E, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE,
	 DMAC_PRV_CHCFG_SET_LVL_EDGE, DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_INT_SSIF_DMA_TX_3, 0x27D, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE,
	 DMAC_PRV_CHCFG_SET_LVL_EDGE, DMAC_PRV_CHCFG_SET_REQD_DST},

	{DMA_RS_SPDIFTXI, 0x283, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_SPDIFRXI, 0x287, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_DST},

	{DMA_RS_INTRIIC_RI0, 0x28A, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_INTRIIC_TI0, 0x289, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_INTRIIC_RI1, 0x28E, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_INTRIIC_TI1, 0x28D, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_INTRIIC_RI2, 0x292, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_INTRIIC_TI2, 0x291, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_INTRIIC_RI3, 0x296, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_INTRIIC_TI3, 0x295, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_SET_REQD_DST},

	{DMA_RS_RXI0, 0x29A, 0x00000400U, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_TXI0, 0x299, 0x00000400U, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_RXI1, 0x29E, 0x00000400U, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_TXI1, 0x29D, 0x00000400U, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_RXI2, 0x2A2, 0x00000400U, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_TXI2, 0x2A1, 0x00000400U, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_RXI3, 0x2A6, 0x00000400U, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_TXI3, 0x2A5, 0x00000400U, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_RXI4, 0x2AA, 0x00000400U, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_TXI4, 0x2A9, 0x00000400U, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_DST},

	{DMA_RS_RXF_DMA0, 0x2AF, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_RXF_DMA1, 0x2B3, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_RXF_DMA2, 0x2B7, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_RXF_DMA3, 0x2BB, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_RXF_DMA4, 0x2BF, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_RXF_DMA5, 0x2C3, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_RXF_DMA6, 0x2C7, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_RXF_DMA7, 0x2CB, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_COM_DMA0, 0x2CF, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},
	{DMA_RS_COM_DMA1, 0x2D3, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},

	{DMA_RS_SPRI0, 0x2D6, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_SPTI0, 0x2D5, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_SPRI1, 0x2DA, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_SPTI1, 0x2D9, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_SPRI2, 0x2DE, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_SPTI2, 0x2DD, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_DST},

	{DMA_RS_SCI_RXI0, 0x2E2, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_SCI_TXI0, 0x2E1, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_SCI_RXI1, 0x2E6, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_SCI_TXI1, 0x2E5, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_SET_REQD_DST},

	{DMA_RS_IPLS, 0x2EB, DMAC_PRV_CHCFG_SET_AM_LEVEL, DMAC_PRV_CHCFG_SET_LVL_EDGE,
	 DMAC_PRV_CHCFG_REQD_UNDEFINED},

	{DMA_RS_TILE_0_PAFI, 0x3CE, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_TILE_0_PAEI, 0x3CD, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_TILE_1_PAFI, 0x3D2, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_TILE_1_PAEI, 0x3D1, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_TILE_2_PAFI, 0x3D6, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_TILE_2_PAEI, 0x3D5, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_TILE_3_PAFI, 0x3DA, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_TILE_3_PAEI, 0x3D9, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_TILE_4_PAFI, 0x3DE, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_TILE_4_PAEI, 0x3DD, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_DST},
	{DMA_RS_TILE_5_PAFI, 0x3E2, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_SRC},
	{DMA_RS_TILE_5_PAEI, 0x3E1, DMAC_PRV_CHCFG_SET_AM_BUS_CYCLE, DMAC_PRV_CHCFG_SET_LVL_LEVEL,
	 DMAC_PRV_CHCFG_SET_REQD_DST},

	{DREQ0, 0x003, 0, 0, DMAC_PRV_CHCFG_REQD_UNDEFINED},

	{LAST_RESOURCE_MARKER, 0, 0, 0, 0},
};

struct dma_rza2_data {
	/* Dma context should be the first in data structure */
	struct dma_context ctx;

	DEVICE_MMIO_NAMED_RAM(reg_main);
	DEVICE_MMIO_NAMED_RAM(ext);

	struct dma_rza2_channel *channels;

	struct rza2_dma_link_descriptor *descr_pool;
	uint32_t descrs_busy;
	struct k_spinlock descr_lock;
};

#define DEV_DATA(dev) ((struct dma_rza2_data *)((dev)->data))
#define DEV_CFG(dev)  ((struct dma_rza2_config *)((dev)->config))

static void rza2_set_n0sa(const struct device *dev, int ch, uint32_t saddr)
{
	sys_write32(saddr, N0SA(dev, ch));
}

static void rza2_set_n0da(const struct device *dev, int ch, uint32_t daddr)
{
	sys_write32(daddr, N0DA(dev, ch));
}

static void rza2_set_n0tb(const struct device *dev, int ch, uint32_t byte_count)
{
	sys_write32(byte_count, N0TB(dev, ch));
}

static uint32_t rza2_get_crtb(const struct device *dev, int ch)
{
	return sys_read32(CRTB(dev, ch));
}

static uint32_t rza2_get_chstat(const struct device *dev, int ch)
{
	return sys_read32(CHSTAT(dev, ch));
}

static void rza2_set_chctrl(const struct device *dev, int ch, uint32_t flag)
{
	sys_write32(flag, CHCTRL(dev, ch));
}

static uint32_t rza2_get_chctrl(const struct device *dev, int ch)
{
	return sys_read32(CHCTRL(dev, ch));
}

static void rza2_set_chcfg(const struct device *dev, int ch, uint32_t value)
{
	sys_write32(value, CHCFG(dev, ch));
}

static uint32_t rza2_get_chcfg(const struct device *dev, int ch)
{
	return sys_read32(CHCFG(dev, ch));
}

static void rza2_set_chitv(const struct device *dev, int ch, uint32_t value)
{
	sys_write32(value, CHITVL(dev, ch));
}

static void rza2_set_chext(const struct device *dev, int ch, uint32_t value)
{
	sys_write32(value, CHEXT(dev, ch));
}

static void rza2_set_nxla(const struct device *dev, int ch, uint32_t value)
{
	sys_write32(value, NXLA(dev, ch));
}

static uint32_t rza2_get_crla(const struct device *dev, int ch)
{
	return sys_read32(CRLA(dev, ch));
}

static void rza2_set_dctrl(const struct device *dev, int ch, uint32_t value)
{
	sys_write32(value, DCTRL(dev, ch));
}

static int rza2_get_ch_state(mem_addr_t addr, int ch)
{
	uint32_t value = sys_read32(addr);
	uint8_t ch_bit = BIT(ch & 7);

	return value & ch_bit;
}

static int rza2_get_ch_err(const struct device *dev, int ch)
{
	return sys_read32(DSTAT_ER(dev, ch));
}

static int rza2_get_ch_sus(const struct device *dev, int ch)
{
	return rza2_get_ch_state(DSTAT_SUS(dev, ch), ch);
}

static void rza2_set_dmars(const struct device *dev, int ch, uint32_t value)
{
	uint32_t dmars32 = sys_read32(DMARS(dev, ch));

	if (ch & 1) {
		dmars32 &= 0x0000ffff;
		dmars32 |= value << 16;
	} else {
		dmars32 &= 0xffff0000;
		dmars32 |= value;
	}

	sys_write32(dmars32, DMARS(dev, ch));
}

static int dma_get_data_size(uint32_t data_size)
{
	switch (data_size) {
	case 1:
		return 0;
	case 2:
		return 1;
	case 4:
		return 2;
	case 8:
		return 3;
	case 16:
		return 4;
	case 32:
		return 5;
	case 64:
		return 6;
	case 128:
		return 7;
	default:
		return -EINVAL;
	}
}

static int get_free_and_set_unlocked(uint32_t *descrs_busy)
{
	int chunk;

	chunk = find_lsb_set(~(*descrs_busy));
	if (chunk && chunk <= CONFIG_DMA_RZA2_DESCRS_CHUNKS) {
		*descrs_busy |= BIT(chunk - 1);
		return chunk - 1;
	}

	return -1;
}

static int free_chunk(const struct device *dev, int chunk)
{
	struct dma_rza2_data *data = dev->data;
	k_spinlock_key_t key;

	if (chunk >= CONFIG_DMA_RZA2_DESCRS_CHUNKS || chunk < 0) {
		return -EINVAL;
	}
	key = k_spin_lock(&data->descr_lock);
	data->descrs_busy &= ~BIT(chunk);
	k_spin_unlock(&data->descr_lock, key);

	return 0;
}

static int get_descrs(const struct device *dev, struct rza2_dma_link_descriptor **descr)
{
	struct dma_rza2_data *data = dev->data;
	int chunk;
	k_spinlock_key_t key;

	if (!descr) {
		return -EINVAL;
	}

	key = k_spin_lock(&data->descr_lock);

	chunk = get_free_and_set_unlocked(&data->descrs_busy);
	if (chunk < 0) {
		*descr = NULL;
	} else {
		*descr = &data->descr_pool[chunk * CONFIG_DMA_RZA2_MAX_DESCRS];
	}
	k_spin_unlock(&data->descr_lock, key);

	return chunk;
}

static bool not_aligned(const struct device *dev, uint32_t addr)
{
	const struct dma_rza2_config *cfg = dev->config;

	if (cfg->addr_alignment == 0) {
		return false;
	}

	return !!(addr & (cfg->addr_alignment - 1));
}

static int rza2_construct_link_chain(const struct device *dev, struct dma_config *dma_cfg,
				     struct dma_rza2_channel *chan, uint32_t ch_cfg)
{
	int i;
	struct dma_block_config *block = dma_cfg->head_block;
	uint32_t total_bytes = 0;

	__ASSERT(chan, "channel should be provided");

	if (!block) {
		LOG_ERR("no dma blocks were provided");
		return -EINVAL;
	}

	chan->chunk = get_descrs(dev, &chan->descrs);
	if (chan->chunk < 0) {
		LOG_ERR("%s: unable to allocate descriptor list for dma transfer", __func__);
		return -ENOMEM;
	}

	for (i = 0; i < dma_cfg->block_count; i++) {
		/* Check source_address and dest_address alignment */
		if ((not_aligned(dev, block->dest_address)) ||
		    (not_aligned(dev, block->source_address))) {
			LOG_ERR("%s: buffers are not properly aligned", __func__);
			free_chunk(dev, chan->chunk);
			return -EINVAL;
		}

		chan->descrs[i].src_addr = Z_MEM_PHYS_ADDR(block->source_address);
		chan->descrs[i].dest_addr = Z_MEM_PHYS_ADDR(block->dest_address);
		chan->descrs[i].trans_byte = block->block_size;
		chan->descrs[i].interval = 0;
		chan->descrs[i].config = ch_cfg;
		chan->descrs[i].header = HDR_LV;

		/* DMA controller supports only 1 interval so apply the bigger one which enabled*/
		if (block->source_gather_en) {
			chan->descrs[i].interval = block->source_gather_interval;
		}

		if (block->dest_scatter_en &&
		    chan->descrs[i].interval < block->dest_scatter_interval) {
			chan->descrs[i].interval = block->dest_scatter_interval;
		}

		/* If this is the last block */
		if (i == dma_cfg->block_count - 1) {
			chan->descrs[i].header = HDR_LV | HDR_LE;
			chan->descrs[i].next_link_address = 0;
		} else {
			chan->descrs[i].next_link_address =
				Z_MEM_PHYS_ADDR((uint32_t)&chan->descrs[i + 1]);
		}

		total_bytes += block->block_size;
		block = block->next_block;
	}

	chan->total_bytes = total_bytes;
	return 0;
}

static void dma_rza2_channel_free(const struct device *dev, struct dma_rza2_channel *ch)
{
	ch->busy = false;
	free_chunk(dev, ch->chunk);
}

static inline int check_ch(const struct device *dev, uint32_t ch)
{
	const struct dma_rza2_config *cfg = dev->config;

	if (ch >= cfg->num_channels) {
		LOG_ERR("channel must be < %" PRIu32 " (%" PRIu32 ")", cfg->num_channels, ch);
		return -EINVAL;
	}

	return 0;
}

static int dma_rza2_config(const struct device *dev, uint32_t channel, struct dma_config *dma_cfg)
{
	int ret;
	struct dma_rza2_data *data = dev->data;
	uint32_t channel_cfg = 0;
	uint32_t channel_ext;
	uint32_t dctrl_cfg = 0;
	struct dma_hw_config hw_config;
	uint32_t interval = 0;
	uint32_t phys_addr;
	k_spinlock_key_t key;

	if (dma_cfg->dma_slot >= LAST_RESOURCE_MARKER) {
		LOG_ERR("Incorrect dma_slot %d was provided to ch %d", dma_cfg->dma_slot, channel);
		return -EINVAL;
	}

	hw_config = dma_hw_config_table[dma_cfg->dma_slot];

	ret = check_ch(dev, channel);
	if (ret < 0) {
		return ret;
	}

	if (dma_cfg->source_chaining_en || dma_cfg->dest_chaining_en) {
		LOG_ERR("Channel chaining is not supported");
		return -EINVAL;
	}

	if (dma_cfg->channel_direction > PERIPHERAL_TO_MEMORY) {
		LOG_ERR("channel_direction must be MEMORY_TO_MEMORY, MEMORY_TO_PERIPHERAL or "
			"PERIPHERAL_TO_MEMORY (%" PRIu32 ")",
			dma_cfg->channel_direction);
		return -ENOTSUP;
	}

	if (dma_cfg->head_block->source_addr_adj != DMA_ADDR_ADJ_INCREMENT &&
	    dma_cfg->head_block->source_addr_adj != DMA_ADDR_ADJ_NO_CHANGE) {
		LOG_ERR("invalid source_addr_adj %" PRIu16, dma_cfg->head_block->source_addr_adj);
		return -ENOTSUP;
	}
	if (dma_cfg->head_block->dest_addr_adj != DMA_ADDR_ADJ_INCREMENT &&
	    dma_cfg->head_block->dest_addr_adj != DMA_ADDR_ADJ_NO_CHANGE) {
		LOG_ERR("invalid dest_addr_adj %" PRIu16, dma_cfg->head_block->dest_addr_adj);
		return -ENOTSUP;
	}

	key = k_spin_lock(&data->channels[channel].lock);

	if (data->channels[channel].busy) {
		ret = -EBUSY;
		goto unlock;
	}

	/* Set sel */
	channel_cfg |= (channel & 0x7u);

	if (dma_cfg->head_block->source_addr_adj != DMA_ADDR_ADJ_INCREMENT) {
		channel_cfg |= DMAC_PRV_CHCFG_MASK_SAD;
	}

	if (dma_cfg->head_block->dest_addr_adj != DMA_ADDR_ADJ_INCREMENT) {
		channel_cfg |= DMAC_PRV_CHCFG_MASK_DAD;
	}

	ret = dma_get_data_size(dma_cfg->dest_data_size);
	if (ret < 0) {
		LOG_ERR("invalid dest_data_size %d\n", dma_cfg->dest_data_size);
		goto unlock;
	}

	channel_cfg |= ((ret << DMAC_PRV_CHCFG_SHIFT_DDS) & DMAC_PRV_CHCFG_MASK_DDS);

	ret = dma_get_data_size(dma_cfg->source_data_size);
	if (ret < 0) {
		LOG_ERR("invalid source_data_size %d\n", dma_cfg->source_data_size);
		goto unlock;
	}

	channel_cfg |= ((ret << DMAC_PRV_CHCFG_SHIFT_SDS) & DMAC_PRV_CHCFG_MASK_SDS);
	data->channels[channel].direction = dma_cfg->channel_direction;

	channel_cfg |= hw_config.tm_am;
	channel_cfg |= hw_config.lvl;

	if (dma_cfg->channel_direction == MEMORY_TO_MEMORY) {
		channel_cfg |= DMAC_PRV_CHCFG_SET_REQD_DST;

		if (dma_cfg->dma_slot != DMA_MEM_2_MEM) {
			LOG_ERR("invalid slot for MEM_2_MEM direction");
		}

		/* Set sw_trigger so transfer will start on Channel Enable */
		data->channels[channel].sw_trigger = 1;
	} else {
		if (hw_config.reqd == DMAC_PRV_CHCFG_REQD_UNDEFINED) {
			if (dma_cfg->channel_direction == PERIPHERAL_TO_MEMORY) {
				channel_cfg |= DMAC_PRV_CHCFG_SET_REQD_DST;
			} else {
				channel_cfg |= DMAC_PRV_CHCFG_SET_REQD_SRC;
			}
		} else {
			channel_cfg |= hw_config.reqd;
		}

		/* HIEN 1 is set for all HW slots */
		channel_cfg |= 1 << DMAC_PRV_CHCFG_SHIFT_HIEN;
	}

	if ((channel_cfg & DMAC_PRV_CHCFG_MASK_REQD) == DMAC_PRV_CHCFG_SET_REQD_SRC) {
		channel_cfg |= 1 << DMAC_PRV_CHCFG_SHIFT_SBE; /* Takes effect only when reqd = 0 */
	}
	/* 0 for Fixed Priority, Round Robin otherwise */
	dctrl_cfg = (dma_cfg->channel_priority == 0);

	if (dma_cfg->block_count > 1) {
		/* Link Mode configuration */
		channel_cfg |= DMAC_PRV_CHCFG_SET_DMS;
		data->channels[channel].mode = LINK_MODE;

		/*
		 * IMPORTANT: channel_cfg value should be set for each descriptor in the linked
		 * list. So current channel_configuration has effect only on start stage. After
		 * loading the descriptor descr->config value will be loaded to CHCFG register.
		 */
		ret = rza2_construct_link_chain(dev, dma_cfg, &data->channels[channel],
						channel_cfg);
		if (ret) {
			goto unlock;
		};

		rza2_set_nxla(dev, channel,
			      Z_MEM_PHYS_ADDR((uint32_t)&data->channels[channel].descrs[0]));
	} else {
		data->channels[channel].mode = REGISTER_MODE;

		/* Check source_address and dest_address alignment */
		if ((not_aligned(dev, dma_cfg->head_block->dest_address)) ||
		    (not_aligned(dev, dma_cfg->head_block->source_address))) {
			LOG_ERR("%s: buffers are not properly aligned", __func__);
			ret = -EINVAL;
			goto unlock;
		}

		rza2_set_n0sa(dev, channel, Z_MEM_PHYS_ADDR(dma_cfg->head_block->source_address));
		rza2_set_n0da(dev, channel, Z_MEM_PHYS_ADDR(dma_cfg->head_block->dest_address));
		rza2_set_n0tb(dev, channel, dma_cfg->head_block->block_size);

		channel_cfg &= ~DMAC_PRV_CHCFG_SET_DMS;  /* Set register mode */
		channel_cfg &= ~DMAC_PRV_CHCFG_SET_REN;  /* Do not switch register set */
		channel_cfg &= ~DMAC_PRV_CHCFG_SET_RSEL; /* Select 0 register set */
		channel_cfg &= ~DMAC_PRV_CHCFG_SET_DEM;  /* Unmask DMA end interrupt */
		channel_cfg &= ~DMAC_PRV_CHCFG_SET_RSW;  /* No automatic register change */
		data->channels[channel].total_bytes = dma_cfg->head_block->block_size;
	}

	if (dma_cfg->head_block->source_gather_en) {
		interval = dma_cfg->head_block->source_gather_interval;
	} else if (dma_cfg->head_block->dest_scatter_en) {
		interval = dma_cfg->head_block->dest_scatter_interval;
	}

	channel_ext = (DMAC_PRV_CHEXT_SET_DPR_NON_SECURE | DMAC_PRV_CHEXT_SET_SPR_NON_SECURE);
	phys_addr = Z_MEM_PHYS_ADDR(dma_cfg->head_block->source_address);
	/* set bus parameter for source */
	if ((phys_addr <= DMAC_PRV_DMA_EXTERNAL_BUS_END) ||
	   ((phys_addr >= DMAC_PRV_DMA_EXTERNAL_BUS_MIRROR_START) &&
	    (phys_addr <= DMAC_PRV_DMA_EXTERNAL_BUS_MIRROR_END))) {
		channel_ext |= DMAC_PRV_CHEXT_SET_SCA_NORMAL;
	} else {
		channel_ext |= DMAC_PRV_CHEXT_SET_SCA_STRONG;
	}
	phys_addr = Z_MEM_PHYS_ADDR(dma_cfg->head_block->dest_address);
	/* set bus parameter for destination */
	if ((phys_addr <= DMAC_PRV_DMA_EXTERNAL_BUS_END) ||
	   ((phys_addr >= DMAC_PRV_DMA_EXTERNAL_BUS_MIRROR_START) &&
	    (phys_addr <= DMAC_PRV_DMA_EXTERNAL_BUS_MIRROR_END))) {
		channel_ext |= DMAC_PRV_CHEXT_SET_DCA_NORMAL;
	} else {
		channel_ext |= DMAC_PRV_CHEXT_SET_DCA_STRONG;
	}

	rza2_set_chcfg(dev, channel, channel_cfg);
	rza2_set_dctrl(dev, channel, dctrl_cfg);
	rza2_set_chitv(dev, channel, interval);
	rza2_set_chext(dev, channel, channel_ext);

	if (dma_cfg->channel_direction != MEMORY_TO_MEMORY) {
		rza2_set_dmars(dev, channel, hw_config.dmars);
	};

	data->channels[channel].dma_callback = dma_cfg->dma_callback;
	data->channels[channel].user_data = dma_cfg->user_data;
	data->channels[channel].err_callback_en = dma_cfg->error_callback_en;
	data->channels[channel].complete_callback_en = dma_cfg->complete_callback_en;

	/* Clear status */
	rza2_set_chctrl(dev, channel, SWRST);
unlock:
	k_spin_unlock(&data->channels[channel].lock, key);
	return ret;
}

static int dma_rza2_start(const struct device *dev, uint32_t ch)
{
	struct dma_rza2_data *data = dev->data;
	int ret;
	uint32_t stat;
	k_spinlock_key_t key;

	ret = check_ch(dev, ch);
	if (ret < 0) {
		return ret;
	}

	key = k_spin_lock(&data->channels[ch].lock);
	if (data->channels[ch].busy) {
		ret = -EBUSY;
		goto unlock;
	}

	stat = rza2_get_chstat(dev, ch);
	if (IS_SET(stat, DMAC_PRV_CHSTAT_MASK_EN) || IS_SET(stat, DMAC_PRV_CHSTAT_MASK_TACT)) {
		ret = -EBUSY;
		goto unlock;
	}

	/* Clear status */
	rza2_set_chctrl(dev, ch, SWRST);

	data->channels[ch].busy = true;

	/* Enable Channel */
	if (data->channels[ch].sw_trigger) {
		rza2_set_chctrl(dev, ch, STG | SETEN);
	} else {
		rza2_set_chctrl(dev, ch, SETEN);
	}

unlock:
	k_spin_unlock(&data->channels[ch].lock, key);

	return ret;
}

static int dma_rza2_stop(const struct device *dev, uint32_t ch)
{
	struct dma_rza2_data *data = dev->data;
	int ret;
	uint32_t ch_cfg;
	k_spinlock_key_t key;

	ret = check_ch(dev, ch);
	if (ret < 0) {
		return ret;
	}

	key = k_spin_lock(&data->channels[ch].lock);
	if (!data->channels[ch].busy) {
		ret = 0;
		goto unlock;
	}

	rza2_set_chctrl(dev, ch, CLREN);

	ch_cfg = rza2_get_chcfg(dev, ch);
	if (IS_SET(ch_cfg, DMAC_PRV_CHCFG_MASK_SBE)) {
		ch_cfg &= ~DMAC_PRV_CHCFG_MASK_REQD;
		rza2_set_chcfg(dev, ch, ch_cfg);
	}

	rza2_set_chctrl(dev, ch, SWRST);

	dma_rza2_channel_free(dev, &data->channels[ch]);
unlock:
	k_spin_unlock(&data->channels[ch].lock, key);
	return ret;
}

static int dma_rza2_suspend(const struct device *dev, uint32_t ch)
{
	int ret;
	struct dma_rza2_data *data = dev->data;
	k_spinlock_key_t key;

	ret = check_ch(dev, ch);
	if (ret < 0) {
		return ret;
	}

	key = k_spin_lock(&data->channels[ch].lock);

	if (!data->channels[ch].busy) {
		return -EINVAL;
	}

	rza2_set_chctrl(dev, ch, SETSUS);

	k_spin_unlock(&data->channels[ch].lock, key);
	return ret;
}

static int dma_rza2_resume(const struct device *dev, uint32_t ch)
{
	int ret;
	struct dma_rza2_data *data = dev->data;
	k_spinlock_key_t key;

	ret = check_ch(dev, ch);
	if (ret < 0) {
		return ret;
	}

	key = k_spin_lock(&data->channels[ch].lock);

	if (!data->channels[ch].busy) {
		ret = -EINVAL;
	} else if (!rza2_get_ch_sus(dev, ch)) {
		ret = -EINVAL;
	} else {
		rza2_set_chctrl(dev, ch, CLRSUS);
	}

	k_spin_unlock(&data->channels[ch].lock, key);
	return ret;
}

static uint32_t get_copied_bytes(struct dma_rza2_channel *chan,
				 struct rza2_dma_link_descriptor *descr)
{
	uint32_t copied_bytes;
	bool found = false;
	struct rza2_dma_link_descriptor *cur = chan->descrs;

	while (cur) {
		if (cur == descr) {
			found = true;
			break;
		}
		copied_bytes += cur->trans_byte;
		cur = (struct rza2_dma_link_descriptor *)Z_MEM_VIRT_ADDR(cur->next_link_address);
	}

	if (!found) {
		LOG_ERR("Current link descriptor lays outside of the channel descriptor list");
		copied_bytes = 0;
	}

	return copied_bytes;
}

static int dma_rza2_get_status(const struct device *dev, uint32_t ch, struct dma_status *stat)
{
	int ret;
	struct dma_rza2_data *data = dev->data;
	struct rza2_dma_link_descriptor *link;
	uint32_t channel_cfg;

	ret = check_ch(dev, ch);
	if (ret < 0) {
		return ret;
	}

	channel_cfg = rza2_get_chcfg(dev, ch);

	stat->busy = data->channels[ch].busy;

	stat->dir = data->channels[ch].direction;

	if (IS_SET(channel_cfg, DMAC_PRV_CHCFG_SET_DMS)) {
		/* For link mode calculate already processed blocks */
		link = (struct rza2_dma_link_descriptor *)Z_MEM_VIRT_ADDR(rza2_get_crla(dev, ch));
		if (link) {
			stat->total_copied = get_copied_bytes(&data->channels[ch], link);
		} else {
			stat->total_copied = 0;
		}

		stat->pending_length = data->channels[ch].total_bytes - stat->total_copied;
	} else {
		/* For register mode get data from CRTB register */
		stat->pending_length = rza2_get_crtb(dev, ch);
		stat->total_copied = data->channels[ch].total_bytes - stat->pending_length;
	}

	return 0;
}

/* TODO get_attributes callback should be implemened */
static const struct dma_driver_api dma_rza2_driver_api = {
	.config = dma_rza2_config,
	.start = dma_rza2_start,
	.stop = dma_rza2_stop,
	.get_status = dma_rza2_get_status,
	.suspend = dma_rza2_suspend,
	.resume = dma_rza2_resume
};

#define DMA_LINK_TR_END        1
#define DMA_LINK_TR_INPROGRESS 0

static int dma_rza2_process_link(const struct device *dev, int ch, uint32_t stat)
{
	struct dma_rza2_data *data = dev->data;
	struct rza2_dma_link_descriptor *link;

	if (data->channels[ch].mode != LINK_MODE) {
		return -EINVAL;
	}

	link = (struct rza2_dma_link_descriptor *)Z_MEM_VIRT_ADDR(rza2_get_crla(dev, ch));
	if (!link) {
		return -EIO;
	}

	if (IS_SET(stat, DMAC_PRV_CHSTAT_MASK_TACT) && !IS_SET(stat, DMAC_PRV_CHSTAT_MASK_DER)) {
		if (data->channels[ch].sw_trigger) {
			rza2_set_chctrl(dev, ch, STG);
		}
	}

	if (!link->header & HDR_LV) {
		return -EIO;
	}

	return (link->header & HDR_LE) ? DMA_LINK_TR_END : DMA_LINK_TR_INPROGRESS;
}

static void dma_rza2_isr_common(const struct device *dev, int ch)
{
	struct dma_rza2_data *data = dev->data;
	uint32_t chctrl;
	uint32_t stat;
	int ret;

	if (check_ch(dev, ch) < 0) {
		LOG_ERR("invalid channel in isr handler");
		return;
	}

	if (!data->channels[ch].busy) {
		LOG_ERR("invalid interrupt, DMA Transfer should be started");
		return;
	}

	stat = rza2_get_chstat(dev, ch);

	if (data->channels[ch].mode == REGISTER_MODE) {
		if (IS_SET(stat, DMAC_PRV_CHSTAT_MASK_ER)) {
			goto err;
		}

		if (!IS_SET(stat, DMAC_PRV_CHSTAT_MASK_END) ||
		    IS_SET(stat, DMAC_PRV_CHSTAT_MASK_EN)) {
			rza2_set_chctrl(dev, ch, CHCTRL_CLEAR);
			dma_rza2_channel_free(dev, &data->channels[ch]);
			if (data->channels[ch].complete_callback_en == 0 &&
			    data->channels[ch].dma_callback) {
				data->channels[ch].dma_callback(dev, data->channels[ch].user_data,
								ch, DMA_STATUS_BLOCK);
			}

			return;
		}

		dma_rza2_channel_free(dev, &data->channels[ch]);
		if (data->channels[ch].complete_callback_en == 0 &&
		    data->channels[ch].dma_callback) {
			data->channels[ch].dma_callback(dev, data->channels[ch].user_data, ch,
							DMA_STATUS_COMPLETE);
		}
	} else if (data->channels[ch].mode == LINK_MODE) {
		if (!IS_SET(stat, DMAC_PRV_CHSTAT_MASK_END) ||
		    IS_SET(stat, DMAC_PRV_CHSTAT_MASK_DER)) {
			goto err;
		}

		ret = dma_rza2_process_link(dev, ch, stat);
		if (ret < 0) {
			goto err;
		}

		/* Send callback for block if needed*/
		if (data->channels[ch].complete_callback_en == 1 &&
		    data->channels[ch].dma_callback) {
			data->channels[ch].dma_callback(dev, data->channels[ch].user_data, ch,
							DMA_STATUS_BLOCK);
		}

		if (ret == DMA_LINK_TR_END && IS_SET(stat, DMAC_PRV_CHSTAT_MASK_EN) == 0) {
			chctrl = rza2_get_chctrl(dev, ch);
			rza2_set_chctrl(dev, ch, chctrl | CLREND);
			dma_rza2_channel_free(dev, &data->channels[ch]);
			/* CALL FINAL CALLBACK*/
			if (data->channels[ch].complete_callback_en == 0 &&
			    data->channels[ch].dma_callback) {
				data->channels[ch].dma_callback(dev, data->channels[ch].user_data,
								ch, DMA_STATUS_COMPLETE);
			}
		}
	}
	return;

err:
	rza2_set_chctrl(dev, ch, CHCTRL_CLEAR);
	dma_rza2_channel_free(dev, &data->channels[ch]);
	if (data->channels[ch].err_callback_en == 0 && data->channels[ch].dma_callback) {
		data->channels[ch].dma_callback(dev, data->channels[ch].user_data, ch, -EIO);
	}
}

static void dma_rza2_err_isr(const struct device *dev)
{
	int err_0_7, err_8_15;
	int ch;
	uint16_t channel_mask;
	const struct dma_rza2_config *config = dev->config;
	struct dma_rza2_data *data = dev->data;

	err_0_7 = rza2_get_ch_err(dev, 0);  /* Same value for all 0..7 channels */
	err_8_15 = rza2_get_ch_err(dev, 8); /* Same value for all 8..15 channels */

	channel_mask = err_0_7 | (err_8_15 << 8);

	for (ch = 0; ch < config->num_channels; ch++) {
		if ((channel_mask & BIT(ch)) && (data->channels[ch].err_callback_en == 0) &&
		    data->channels[ch].dma_callback) {
			data->channels[ch].dma_callback(dev, data->channels[ch].user_data, ch,
							DMA_STATUS_BLOCK);
			dma_rza2_channel_free(dev, &data->channels[ch]);
		}
	}
}

static int dma_rza2_init(const struct device *dev)
{
	const struct dma_rza2_config *cfg = dev->config;
	int ret;

#ifdef CONFIG_PINCTRL
	ret = pinctrl_apply_state(cfg->pcfg, PINCTRL_STATE_DEFAULT);
	if (ret < 0) {
		LOG_ERR("unable to configure DMA pins");
		return -EINVAL;
	}
#endif

	DEVICE_MMIO_NAMED_MAP(dev, reg_main, K_MEM_CACHE_NONE);
	DEVICE_MMIO_NAMED_MAP(dev, ext, K_MEM_CACHE_NONE);

	cfg->irq_configure();

	return 0;
}

#define IRQ_ERR_CONFIGURE(inst, name)                                                              \
	IRQ_CONNECT(DT_INST_IRQ_BY_NAME(inst, name, irq),                                          \
		    DT_INST_IRQ_BY_NAME(inst, name, priority), dma_rza2_err_isr,                   \
		    DEVICE_DT_INST_GET(inst), DT_INST_IRQ_BY_NAME(inst, name, flags));             \
	irq_enable(DT_INST_IRQ_BY_NAME(inst, name, irq));

#define IRQ_DECLARE_ISR(n, inst)                                                                   \
	static void dma_rza2_##n##_##inst##_isr(const struct device *dev)                          \
	{                                                                                          \
		dma_rza2_isr_common(dev, n);                                                       \
	}

#define IRQ_CONFIGURE(n, inst)                                                                     \
	IRQ_CONNECT(DT_INST_IRQ_BY_IDX(inst, n, irq), DT_INST_IRQ_BY_IDX(inst, n, priority),       \
		    dma_rza2_##n##_##inst##_isr, DEVICE_DT_INST_GET(inst),                         \
		    DT_INST_IRQ_BY_IDX(inst, n, flags));                                           \
	irq_enable(DT_INST_IRQ_BY_IDX(inst, n, irq));

#define CONFIGURE_ALL_IRQS(inst, n) LISTIFY(n, IRQ_CONFIGURE, (), inst)

#define DECLARE_ALL_IRQS(inst, n) LISTIFY(n, IRQ_DECLARE_ISR, (), inst)

#define DMA_RZA2_POOL_SIZE CONFIG_DMA_RZA2_MAX_DESCRS * CONFIG_DMA_RZA2_DESCRS_CHUNKS

#ifdef CONFIG_PINCTRL
#define RZ_PINCTRL_DT_INST_DEFINE(n)                                                               \
	COND_CODE_1(DT_INST_NUM_PINCTRL_STATES(n), (PINCTRL_DT_INST_DEFINE(n);), (EMPTY))
#define RZ_PINCTRL_DT_INST_DEV_CONFIG_GET(n)                                                       \
	COND_CODE_1(DT_INST_PINCTRL_HAS_IDX(n, 0), (PINCTRL_DT_INST_DEV_CONFIG_GET(n)), (NULL))
#else
#define RZ_PINCTRL_DT_INST_DEFINE(n)
#define RZ_PINCTRL_DT_INST_DEV_CONFIG_GET(n) NULL
#endif

#define RZA2_DMA_INIT(inst)                                                                        \
	DECLARE_ALL_IRQS(inst, DT_INST_PROP(inst, dma_channels))                                   \
                                                                                                   \
	static void dma_rza2_##inst##_irq_configure(void)                                          \
	{                                                                                          \
		CONFIGURE_ALL_IRQS(inst, DT_INST_PROP(inst, dma_channels));                        \
                                                                                                   \
		COND_CODE_1(DT_INST_IRQ_HAS_NAME(inst, err0), (IRQ_ERR_CONFIGURE(inst, err0)), ()) \
		COND_CODE_1(DT_INST_IRQ_HAS_NAME(inst, err1), (IRQ_ERR_CONFIGURE(inst, err1)), ()) \
	}                                                                                          \
                                                                                                   \
	RZ_PINCTRL_DT_INST_DEFINE(inst);                                                           \
                                                                                                   \
	static const struct dma_rza2_config dma_rza2_##inst##_config = {                           \
		DEVICE_MMIO_NAMED_ROM_INIT_BY_NAME(reg_main, DT_DRV_INST(inst)),                   \
		DEVICE_MMIO_NAMED_ROM_INIT_BY_NAME(ext, DT_DRV_INST(inst)),                        \
		.num_channels = DT_INST_PROP(inst, dma_channels),                                  \
		.irq_configure = dma_rza2_##inst##_irq_configure,                                  \
		.pcfg = RZ_PINCTRL_DT_INST_DEV_CONFIG_GET(inst),                                   \
		.addr_alignment = DMA_BUF_ADDR_ALIGNMENT(DT_DRV_INST(inst)),                       \
	};                                                                                         \
                                                                                                   \
	static __aligned(DMA_BUF_ADDR_ALIGNMENT(DT_DRV_INST(inst)))                                \
		struct rza2_dma_link_descriptor descr_##inst##_pool[DMA_RZA2_POOL_SIZE]            \
		__attribute__((__section__(".nocache.dma"))) = {0};                                \
                                                                                                   \
	static struct dma_rza2_channel                                                             \
		dma_rza2_##inst##_channels[DT_INST_PROP(inst, dma_channels)];                      \
	ATOMIC_DEFINE(dma_rza2_atomic##inst, DT_INST_PROP(inst, dma_channels));                    \
                                                                                                   \
	static struct dma_rza2_data dma_rza2_##inst##_data = {                                     \
		.ctx =                                                                             \
			{                                                                          \
				.magic = DMA_MAGIC,                                                \
				.atomic = dma_rza2_atomic##inst,                                   \
				.dma_channels = DT_INST_PROP(inst, dma_channels),                  \
			},                                                                         \
		.channels = dma_rza2_##inst##_channels,                                            \
		.descr_pool = descr_##inst##_pool,                                                 \
		.descrs_busy = 0,                                                                  \
	};                                                                                         \
                                                                                                   \
	DEVICE_DT_INST_DEFINE(inst, dma_rza2_init, NULL, &dma_rza2_##inst##_data,                  \
			      &dma_rza2_##inst##_config, PRE_KERNEL_1,                             \
			      CONFIG_DMA_RZA2_INIT_PRIORITY, &dma_rza2_driver_api);

DT_INST_FOREACH_STATUS_OKAY(RZA2_DMA_INIT)
